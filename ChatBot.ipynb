{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lzORSJVMTA7"
      },
      "source": [
        "import nltk\r\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_64SwrEObx2"
      },
      "source": [
        "BOT_CONFIG = {\r\n",
        "    \"intents\": { # Намерения\r\n",
        "        \"hello\": { # Намерение поздароваться\r\n",
        "            \"examples\": [\"Привет\", \"Добрый день\", \"Шалом\", \"Здравствуйте\"],\r\n",
        "            \"responses\": [\"Привет, человек\", \"Доброго времени суток\"]\r\n",
        "        },\r\n",
        "        \"bye\": {\r\n",
        "            \"examples\": [\"Пока\", \"Досвидос\", \"Прощай\"],\r\n",
        "            \"responses\": [\"Счастливо\", \"До свидания\", \"Если что, возвращайтесь\"],\r\n",
        "        },\r\n",
        "        \"howdoyoudo\": {\r\n",
        "            \"examples\": [\"Как дела\", \"Что делаешь\", \"Какие дела\"],\r\n",
        "            \"responses\": [\"Маюсь фигней\", \"Отвечаю на дурацкие вопросы\", \"Веду вебинары\"],\r\n",
        "        },\r\n",
        "    },\r\n",
        "    \"failure_phrases\": [\r\n",
        "        \"Я ничо не понил\",\r\n",
        "        \"Что-то непонятно\",\r\n",
        "        \"Я всего лишь бот, сформулируйте попроще\"\r\n",
        "    ]\r\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygzRe-VdOczL"
      },
      "source": [
        "def filter(text):\r\n",
        "  text = text.lower()\r\n",
        "  text = [c for c in text if c in 'абвгджзеёийклмнопрстуфхцчшщьыъэюя -']\r\n",
        "  return ''.join(text)\r\n",
        "\r\n",
        "def match(text, example): # \"прощяй!\" === \"Прощай\" ??\r\n",
        "  text = filter(text)\r\n",
        "  #example = filter(example)\r\n",
        "  \r\n",
        "  distance = nltk.edit_distance(text, example) / len(example)\r\n",
        "  if distance < 0.4:\r\n",
        "    return True # Текст совпадает\r\n",
        "  else:\r\n",
        "    return False # Текст НЕ совпадает"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki5vifRvOgBD"
      },
      "source": [
        "def get_intent(text): \r\n",
        "  for intent, data in BOT_CONFIG['intents'].items():\r\n",
        "    for example in data['examples']:\r\n",
        "      if match(text, example):\r\n",
        "        return intent"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn8AbBGYOiaz"
      },
      "source": [
        "def get_answer_by_intent(intent):\r\n",
        "  phrases = BOT_CONFIG['intents'][intent]['responses']\r\n",
        "  return random.choice(phrases)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBhSHyvY859h"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho1Sa4nhOkSa"
      },
      "source": [
        "def bot(text):\r\n",
        "  # 1. Понять намерение\r\n",
        "  intent = get_intent(text)\r\n",
        "\r\n",
        "  if not intent:\r\n",
        "    intent = get_intent_predictive_model(text)\r\n",
        "\r\n",
        "  if intent:\r\n",
        "    return get_answer_by_intent(intent)\r\n",
        "\r\n",
        "  \r\n",
        "\r\n",
        "  # 3. Отвечаем \"заглушкой\"\r\n",
        "  failure_phrases = BOT_CONFIG['failure_phrases']\r\n",
        "  return random.choice(failure_phrases)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "X4KLL2xKOmRj",
        "outputId": "6c011ff2-a4aa-4ab6-d9af-e6de8d3722dd"
      },
      "source": [
        "question = ''\r\n",
        "while question not in ['выход', 'отстань']:\r\n",
        "  question = input()\r\n",
        "  answer = bot(question)\r\n",
        "  print(answer)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "выход\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a5a438811c22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'выход'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'отстань'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6aa8c862390b>\u001b[0m in \u001b[0;36mbot\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mintent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mintent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_intent_predictive_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mintent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_intent_predictive_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sto6dibOoGr"
      },
      "source": [
        "import json"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN30xuXAsGv_"
      },
      "source": [
        "config_file = open('/content/big_bot_config.json', \"r\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqeYNMo_siDs"
      },
      "source": [
        "BOT_CONFIG = json.load(config_file)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMfx6ryVsx9W",
        "outputId": "c8ece54d-bc48-485e-ee31-239a3dc06862"
      },
      "source": [
        "len(BOT_CONFIG['intents'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "439"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A03euWWSs3sV"
      },
      "source": [
        "BOT_CONFIG['intents']['hello']['examples']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dssoEtuZtGN8"
      },
      "source": [
        "X_examples = []\r\n",
        "y = []\r\n",
        "for intent, data in BOT_CONFIG['intents'].items():\r\n",
        "  for example in data['examples']:\r\n",
        "    X_examples.append(example)\r\n",
        "    y.append(intent)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYP7SroLy6rv",
        "outputId": "f153ccd6-6a79-4656-fe0d-267fcef37bfa"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "count_vectorizer = CountVectorizer()\r\n",
        "count_vectorizer.fit(X_examples)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qh3SPWjzcX7"
      },
      "source": [
        "# list(count_vectorizer.transform(['чем ты там занимаешься']).nonzero()[1])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHCqd9XHzopi"
      },
      "source": [
        "X = count_vectorizer.transform(X_examples)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGpb6z2-1-Pg"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OjztZ3G1_p3",
        "outputId": "1af3e581-efa9-4e93-a044-0370f27235a1"
      },
      "source": [
        "log_reg = LogisticRegression()\r\n",
        "log_reg.fit(X, y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSyoI3lT2BdP",
        "outputId": "134b799e-d999-4fe9-a47b-603eddf722d8"
      },
      "source": [
        "log_reg.predict(count_vectorizer.transform(['чем ты там занимаешься']))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['byflood'], dtype='<U29')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k8mobEA2yZo",
        "outputId": "b8a640f5-adad-456f-ef58-65343481a765"
      },
      "source": [
        "log_reg.score(X, y)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38840772818121255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iANz5Z_f3aL9"
      },
      "source": [
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9-9DHMX4BNr"
      },
      "source": [
        "# X_train Тренировочная выборка\r\n",
        "# X_test тестовая выборка"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP-RJkeQ9ar3"
      },
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfnG1xjj9k1v"
      },
      "source": [
        "hashing_vectorizer = HashingVectorizer()\r\n",
        "X = hashing_vectorizer.fit_transform(X_examples)\r\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMnqdc1c-LzU"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "TFV = TfidfVectorizer(analyzer='char_wb', ngram_range=(2,4))\r\n",
        "X = TFV.fit_transform(X_examples)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExFiQLax6gzg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(\r\n",
        "    X, y, test_size=0.33\r\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCUxZrex31XM",
        "outputId": "b3382d0e-7908-4cad-9df5-8f2eb7c2aef2"
      },
      "source": [
        "lin_svc = LinearSVC()\r\n",
        "lin_svc.fit(X_train, y_train)\r\n",
        "print ('Train', lin_svc.score(X_train, y_train))\r\n",
        "print ('Test', lin_svc.score(X_test, y_test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train 0.8617603182496271\n",
            "Test 0.34006054490413723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpGGNp4M7j-n"
      },
      "source": [
        "def get_intent_predictive_model(text):\r\n",
        "  return lin_svc.predict(TFV.transform([text]))[0]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2N1FfSvFG3j"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0OCYkqNFJw4"
      },
      "source": [
        "pickle.dump(lin_svc, open('lin_svc.model', 'wb'))\r\n",
        "pickle.dump(TFV, open('TFV.model', 'wb'))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YSjB5u1KJeK"
      },
      "source": [
        "vctrzr = pickle.load(open('lin_svc.model', 'rb'))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93lElScGgdnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10ae83c-3328-4f91-8385-6552d6ed9cb0"
      },
      "source": [
        "! pip install python-telegram-bot --upgrade"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-telegram-bot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/b3/f363e9c5c2e4690a1fd352c01263eb2938952888c09d73c824b49d288dcc/python_telegram_bot-13.1-py3-none-any.whl (422kB)\n",
            "\u001b[K     |████████████████████████████████| 430kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: decorator>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2018.6 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (5.1.1)\n",
            "Collecting APScheduler==3.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/34/9ef20ed473c4fd2c3df54ef77a27ae3fc7500b16b192add4720cab8b2c09/APScheduler-3.6.3-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.9MB/s \n",
            "\u001b[?25hCollecting cryptography\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/de/7054df0620b5411ba45480f0261e1fb66a53f3db31b28e3aa52c026e72d9/cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 14.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=0.7 in /usr/local/lib/python3.6/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (51.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tzlocal>=1.2 in /usr/local/lib/python3.6/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.5.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot) (1.14.4)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography->python-telegram-bot) (2.20)\n",
            "Installing collected packages: APScheduler, cryptography, python-telegram-bot\n",
            "Successfully installed APScheduler-3.6.3 cryptography-3.3.1 python-telegram-bot-13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhso4QRU28MB"
      },
      "source": [
        "from telegram import Update\r\n",
        "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMxjKS7v3r4V"
      },
      "source": [
        "def start(update: Update, context: CallbackContext) -> None:\r\n",
        "    \"\"\"Send a message when the command /start is issued.\"\"\"\r\n",
        "    update.message.reply_text('Кукуськи, пуська!')\r\n",
        "\r\n",
        "\r\n",
        "def help_command(update: Update, context: CallbackContext) -> None:\r\n",
        "    \"\"\"Send a message when the command /help is issued.\"\"\"\r\n",
        "    update.message.reply_text('Help!')\r\n",
        "\r\n",
        "\r\n",
        "def echo(update: Update, context: CallbackContext) -> None:\r\n",
        "    \"\"\"Echo the user message.\"\"\"\r\n",
        "    answer = bot(update.message.text)\r\n",
        "    update.message.reply_text(answer)\r\n",
        "\r\n",
        "\r\n",
        "def main():\r\n",
        "    \"\"\"Start the bot.\"\"\"\r\n",
        "    # Create the Updater and pass it your bot's token.\r\n",
        "    # Make sure to set use_context=True to use the new context based callbacks\r\n",
        "    # Post version 12 this will no longer be necessary\r\n",
        "    updater = Updater(\"1311062782:AAHVB0rcTMuXQjIBLSO9IJ1IzD3hFSfszhg\", use_context=True)\r\n",
        "\r\n",
        "    # Get the dispatcher to register handlers\r\n",
        "    dispatcher = updater.dispatcher\r\n",
        "\r\n",
        "    # on different commands - answer in Telegram\r\n",
        "    dispatcher.add_handler(CommandHandler(\"start\", start))\r\n",
        "    dispatcher.add_handler(CommandHandler(\"help\", help_command))\r\n",
        "\r\n",
        "    # on noncommand i.e message - echo the message on Telegram\r\n",
        "    dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, echo))\r\n",
        "\r\n",
        "    # Start the Bot\r\n",
        "    updater.start_polling()\r\n",
        "\r\n",
        "    # Run the bot until you press Ctrl-C or the process receives SIGINT,\r\n",
        "    # SIGTERM or SIGABRT. This should be used most of the time, since\r\n",
        "    # start_polling() is non-blocking and will stop the bot gracefully.\r\n",
        "    updater.idle()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciiG15l34vLs"
      },
      "source": [
        "main()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHLhlfxL8iJt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}